#!/usr/bin/env python3
"""
äº¤äº’é¡¹Coxå›å½’å‡è®¾æ£€éªŒ
ä¸“é—¨æ£€éªŒåŒ…å«äº¤äº’é¡¹çš„Coxæ¨¡å‹æ˜¯å¦æ»¡è¶³æ¯”ä¾‹é£é™©å‡è®¾
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from lifelines import CoxPHFitter
from lifelines.statistics import proportional_hazard_test
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# å¯¼å…¥ç°æœ‰çš„åˆ†ææ¨¡å—
import sys
import os
sys.path.append(os.path.dirname(__file__))
from src.modeling.baseline import BaselineModeling

class InteractionCoxDiagnostics:
    """äº¤äº’é¡¹Coxå›å½’æ¨¡å‹è¯Šæ–­ç±»"""
    
    def __init__(self):
        self.data = None
        self.baseline_model = None
        self.interaction_model = None
        self.fitted_baseline = False
        self.fitted_interaction = False
        
    def load_and_prepare_data(self):
        """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
        print("ğŸ“Š åŠ è½½åŒ…å«äº¤äº’é¡¹çš„Coxæ¨¡å‹æ•°æ®...")
        
        try:
            baseline = BaselineModeling()
            baseline.load_data()
            
            # åˆå¹¶æ‰€æœ‰æ¨¡å‹æ•°æ®
            combined_data = []
            for model_name, model_data in baseline.models_data.items():
                long_df = model_data['long'].copy()
                long_df['model'] = model_name
                
                required_cols = ['round', 'failure', 'conversation_id', 'model', 
                               'prompt_to_prompt_drift', 'context_to_prompt_drift', 
                               'cumulative_drift', 'prompt_complexity']
                
                available_cols = [col for col in required_cols if col in long_df.columns]
                model_subset = long_df[available_cols].copy()
                model_subset = model_subset.dropna()
                
                if len(model_subset) > 0:
                    combined_data.append(model_subset)
            
            self.data = pd.concat(combined_data, ignore_index=True)
            
            # åˆ›å»ºæ¨¡å‹è™šæ‹Ÿå˜é‡
            model_dummies = pd.get_dummies(self.data['model'], prefix='model', drop_first=True)
            self.data = pd.concat([self.data, model_dummies], axis=1)
            
            # åˆ›å»ºäº¤äº’é¡¹
            self.create_interaction_terms()
            
            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(self.data)} è§‚æµ‹å€¼, {len(self.data['model'].unique())} ä¸ªæ¨¡å‹")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def create_interaction_terms(self):
        """åˆ›å»ºäº¤äº’é¡¹"""
        print("âš¡ åˆ›å»ºäº¤äº’é¡¹...")
        
        drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                     'cumulative_drift', 'prompt_complexity']
        model_vars = [col for col in self.data.columns if col.startswith('model_')]
        
        interaction_count = 0
        for drift_var in drift_vars:
            for model_var in model_vars:
                interaction_name = f"{drift_var}_x_{model_var}"
                self.data[interaction_name] = self.data[drift_var] * self.data[model_var]
                interaction_count += 1
        
        print(f"âœ… åˆ›å»ºäº† {interaction_count} ä¸ªäº¤äº’é¡¹")
    
    def fit_baseline_model(self):
        """æ‹ŸåˆåŸºç¡€æ¨¡å‹ï¼ˆæ— äº¤äº’é¡¹ï¼‰"""
        print("\nğŸ”§ æ‹ŸåˆåŸºç¡€Coxå›å½’æ¨¡å‹ï¼ˆæ— äº¤äº’é¡¹ï¼‰...")
        
        drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                     'cumulative_drift', 'prompt_complexity']
        model_vars = [col for col in self.data.columns if col.startswith('model_')]
        
        baseline_vars = drift_vars + model_vars + ['round', 'failure']
        baseline_data = self.data[baseline_vars].copy()
        
        self.baseline_model = CoxPHFitter(penalizer=0.01)
        self.baseline_model.fit(baseline_data, duration_col='round', event_col='failure', show_progress=False)
        
        self.fitted_baseline = True
        print(f"âœ… åŸºç¡€æ¨¡å‹æ‹Ÿåˆå®Œæˆ (C-index: {self.baseline_model.concordance_index_:.4f})")
        
        return self.baseline_model
    
    def fit_interaction_model(self):
        """æ‹Ÿåˆäº¤äº’é¡¹æ¨¡å‹"""
        print("\nğŸ”§ æ‹Ÿåˆäº¤äº’é¡¹Coxå›å½’æ¨¡å‹...")
        
        # è·å–æ‰€æœ‰ç‰¹å¾ï¼ˆåŒ…æ‹¬äº¤äº’é¡¹ï¼‰
        drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                     'cumulative_drift', 'prompt_complexity']
        model_vars = [col for col in self.data.columns if col.startswith('model_')]
        interaction_vars = [col for col in self.data.columns if '_x_model_' in col]
        
        all_vars = drift_vars + model_vars + interaction_vars + ['round', 'failure']
        interaction_data = self.data[all_vars].copy()
        
        print(f"   åŒ…å«ç‰¹å¾: {len(drift_vars)} æ¼‚ç§» + {len(model_vars)} æ¨¡å‹ + {len(interaction_vars)} äº¤äº’é¡¹")
        
        self.interaction_model = CoxPHFitter(penalizer=0.05)  # å¢åŠ æ­£åˆ™åŒ–
        self.interaction_model.fit(interaction_data, duration_col='round', event_col='failure', show_progress=False)
        
        self.fitted_interaction = True
        print(f"âœ… äº¤äº’æ¨¡å‹æ‹Ÿåˆå®Œæˆ (C-index: {self.interaction_model.concordance_index_:.4f})")
        
        return self.interaction_model
    
    def test_interaction_proportional_hazards(self):
        """æ£€éªŒäº¤äº’é¡¹æ¨¡å‹çš„æ¯”ä¾‹é£é™©å‡è®¾"""
        print("\nğŸ§ª æ£€éªŒäº¤äº’é¡¹æ¨¡å‹çš„æ¯”ä¾‹é£é™©å‡è®¾")
        print("=" * 60)
        
        if not self.fitted_interaction:
            print("âŒ è¯·å…ˆæ‹Ÿåˆäº¤äº’é¡¹æ¨¡å‹")
            return
        
        try:
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                         'cumulative_drift', 'prompt_complexity']
            model_vars = [col for col in self.data.columns if col.startswith('model_')]
            interaction_vars = [col for col in self.data.columns if '_x_model_' in col]
            
            all_vars = drift_vars + model_vars + interaction_vars + ['round', 'failure']
            test_data = self.data[all_vars].copy()
            
            # ç”±äºäº¤äº’é¡¹æ¨¡å‹å¤æ‚ï¼Œä½¿ç”¨æ‰‹åŠ¨Schoenfeldæ®‹å·®æ£€éªŒ
            print("ğŸ”„ ä½¿ç”¨Schoenfeldæ®‹å·®è¿›è¡Œæ¯”ä¾‹é£é™©æ£€éªŒ...")
            self.manual_interaction_ph_test(test_data)
            
        except Exception as e:
            print(f"âŒ äº¤äº’é¡¹æ¯”ä¾‹é£é™©æ£€éªŒå¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•åˆ†ç»„æ£€éªŒ...")
            self.grouped_ph_test()
    
    def manual_interaction_ph_test(self, test_data):
        """åŸºäºSchoenfeldæ®‹å·®çš„äº¤äº’é¡¹æ¯”ä¾‹é£é™©æ£€éªŒ"""
        try:
            from scipy.stats import pearsonr
            
            # è®¡ç®—Schoenfeldæ®‹å·®
            schoenfeld_resid = self.interaction_model.compute_residuals(test_data, kind='schoenfeld')
            
            print("äº¤äº’é¡¹Schoenfeldæ®‹å·®æ£€éªŒç»“æœ:")
            
            # åˆ†ç±»æ£€éªŒä¸åŒç±»å‹çš„ç‰¹å¾
            feature_categories = {
                'åŸºç¡€æ¼‚ç§»ç‰¹å¾': ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                              'cumulative_drift', 'prompt_complexity'],
                'æ¨¡å‹è™šæ‹Ÿå˜é‡': [col for col in schoenfeld_resid.columns if col.startswith('model_') and '_x_' not in col],
                'äº¤äº’é¡¹ç‰¹å¾': [col for col in schoenfeld_resid.columns if '_x_model_' in col]
            }
            
            times = test_data['round']
            category_violations = {}
            
            for category, features in feature_categories.items():
                print(f"\nã€{category}ã€‘:")
                violations = []
                
                for feature in features:
                    if feature in schoenfeld_resid.columns:
                        residuals = schoenfeld_resid[feature]
                        
                        # ç§»é™¤NaNå€¼
                        mask = ~(np.isnan(residuals) | np.isnan(times))
                        if mask.sum() < 10:
                            continue
                        
                        clean_resid = residuals[mask]
                        clean_times = times[mask]
                        
                        try:
                            corr, p_val = pearsonr(clean_times, clean_resid)
                            status = "âŒ è¿å" if p_val < 0.05 else "âœ… ç¬¦åˆ"
                            print(f"  {feature}: r={corr:.4f}, p={p_val:.6f} {status}")
                            
                            if p_val < 0.05:
                                violations.append(feature)
                        except:
                            continue
                
                category_violations[category] = violations
            
            # æ€»ç»“å„ç±»åˆ«çš„è¿åæƒ…å†µ
            print(f"\n=== æ¯”ä¾‹é£é™©å‡è®¾è¿åæ€»ç»“ ===")
            for category, violations in category_violations.items():
                total_features = len(feature_categories[category])
                violation_count = len(violations)
                violation_rate = violation_count / total_features * 100 if total_features > 0 else 0
                
                print(f"{category}: {violation_count}/{total_features} ({violation_rate:.1f}%) è¿åå‡è®¾")
                
                if violations:
                    print(f"  è¿åçš„ç‰¹å¾: {', '.join(violations[:3])}{'...' if len(violations) > 3 else ''}")
            
            # ç‰¹åˆ«å…³æ³¨äº¤äº’é¡¹
            interaction_violations = category_violations.get('äº¤äº’é¡¹ç‰¹å¾', [])
            if interaction_violations:
                print(f"\nâš ï¸  {len(interaction_violations)} ä¸ªäº¤äº’é¡¹è¿åæ¯”ä¾‹é£é™©å‡è®¾")
                print("è¿™å¯èƒ½æ„å‘³ç€:")
                print("  1. äº¤äº’æ•ˆåº”æœ¬èº«éšæ—¶é—´å˜åŒ–")
                print("  2. éœ€è¦è€ƒè™‘ä¸‰é˜¶äº¤äº’ï¼ˆç‰¹å¾Ã—æ¨¡å‹Ã—æ—¶é—´ï¼‰")
                print("  3. æ¨¡å‹å¯èƒ½è¿‡åº¦å¤æ‚åŒ–")
            else:
                print(f"\nâœ… äº¤äº’é¡¹åŸºæœ¬ç¬¦åˆæ¯”ä¾‹é£é™©å‡è®¾")
                
        except Exception as e:
            print(f"âŒ æ‰‹åŠ¨äº¤äº’é¡¹æ£€éªŒå¤±è´¥: {e}")
    
    def grouped_ph_test(self):
        """åˆ†ç»„æ¯”ä¾‹é£é™©æ£€éªŒ"""
        print("\nğŸ”„ åˆ†ç»„æ¯”ä¾‹é£é™©æ£€éªŒ...")
        
        try:
            # åªæ£€éªŒæœ€é‡è¦çš„äº¤äº’é¡¹
            significant_interactions = [
                'prompt_to_prompt_drift_x_model_deepseek_r1',
                'prompt_to_prompt_drift_x_model_mistral_large',
                'prompt_to_prompt_drift_x_model_qwen_max'
            ]
            
            for interaction in significant_interactions:
                if interaction in self.data.columns:
                    print(f"\næ£€éªŒ {interaction}:")
                    
                    # åˆ›å»ºç®€åŒ–æ•°æ®é›†
                    simple_vars = ['prompt_to_prompt_drift', interaction, 'round', 'failure']
                    simple_data = self.data[simple_vars].copy().dropna()
                    
                    if len(simple_data) > 100:
                        # æ‹Ÿåˆç®€åŒ–æ¨¡å‹
                        simple_model = CoxPHFitter()
                        simple_model.fit(simple_data, duration_col='round', event_col='failure', show_progress=False)
                        
                        # è®¡ç®—æ®‹å·®
                        residuals = simple_model.compute_residuals(simple_data, kind='schoenfeld')
                        times = simple_data['round']
                        
                        for col in residuals.columns:
                            if col == interaction:
                                mask = ~(np.isnan(residuals[col]) | np.isnan(times))
                                if mask.sum() > 10:
                                    corr, p_val = pearsonr(times[mask], residuals[col][mask])
                                    status = "âŒ è¿å" if p_val < 0.05 else "âœ… ç¬¦åˆ"
                                    print(f"  {col}: p={p_val:.6f} {status}")
        
        except Exception as e:
            print(f"åˆ†ç»„æ£€éªŒå¤±è´¥: {e}")
    
    def compare_models(self):
        """æ¯”è¾ƒåŸºç¡€æ¨¡å‹å’Œäº¤äº’é¡¹æ¨¡å‹"""
        print("\nğŸ“ˆ æ¨¡å‹æ¯”è¾ƒåˆ†æ")
        print("=" * 50)
        
        if not (self.fitted_baseline and self.fitted_interaction):
            print("âŒ è¯·å…ˆæ‹Ÿåˆä¸¤ä¸ªæ¨¡å‹")
            return
        
        print("åŸºç¡€æ¨¡å‹ vs äº¤äº’é¡¹æ¨¡å‹:")
        print(f"  åŸºç¡€æ¨¡å‹ C-index: {self.baseline_model.concordance_index_:.4f}")
        print(f"  äº¤äº’æ¨¡å‹ C-index: {self.interaction_model.concordance_index_:.4f}")
        print(f"  æ”¹è¿›å¹…åº¦: {(self.interaction_model.concordance_index_ - self.baseline_model.concordance_index_)*100:.2f}%")
        
        print(f"\n  åŸºç¡€æ¨¡å‹ AIC: {self.baseline_model.AIC_partial_:.2f}")
        print(f"  äº¤äº’æ¨¡å‹ AIC: {self.interaction_model.AIC_partial_:.2f}")
        
        aic_improvement = self.baseline_model.AIC_partial_ - self.interaction_model.AIC_partial_
        print(f"  AICæ”¹è¿›: {aic_improvement:.2f} ({'æ›´å¥½' if aic_improvement > 0 else 'æ›´å·®'})")
        
        # ä¼¼ç„¶æ¯”æ£€éªŒ
        try:
            lr_stat = -2 * (self.baseline_model.log_likelihood_ - self.interaction_model.log_likelihood_)
            # äº¤äº’é¡¹æ•°é‡ä½œä¸ºè‡ªç”±åº¦
            interaction_count = len([col for col in self.data.columns if '_x_model_' in col])
            
            from scipy.stats import chi2
            p_value = 1 - chi2.cdf(lr_stat, interaction_count)
            
            print(f"\nä¼¼ç„¶æ¯”æ£€éªŒ:")
            print(f"  LRç»Ÿè®¡é‡: {lr_stat:.4f}")
            print(f"  è‡ªç”±åº¦: {interaction_count}")
            print(f"  på€¼: {p_value:.2e}")
            print(f"  ç»“è®º: {'äº¤äº’é¡¹æ˜¾è‘—æ”¹å–„æ¨¡å‹' if p_value < 0.05 else 'äº¤äº’é¡¹æ”¹å–„ä¸æ˜¾è‘—'}")
            
        except Exception as e:
            print(f"ä¼¼ç„¶æ¯”æ£€éªŒå¤±è´¥: {e}")
    
    def comprehensive_interaction_diagnostics(self):
        """è¿è¡Œå®Œæ•´çš„äº¤äº’é¡¹è¯Šæ–­"""
        print("ğŸ§ª äº¤äº’é¡¹Coxå›å½’æ¨¡å‹å®Œæ•´è¯Šæ–­")
        print("=" * 80)
        
        # åŠ è½½æ•°æ®
        if not self.load_and_prepare_data():
            return
        
        # æ‹Ÿåˆä¸¤ä¸ªæ¨¡å‹
        self.fit_baseline_model()
        self.fit_interaction_model()
        
        print("=" * 80)
        
        # æ¯”ä¾‹é£é™©å‡è®¾æ£€éªŒ
        self.test_interaction_proportional_hazards()
        
        print("=" * 80)
        
        # æ¨¡å‹æ¯”è¾ƒ
        self.compare_models()
        
        print("=" * 80)
        print("ğŸ‰ äº¤äº’é¡¹è¯Šæ–­å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    diagnostics = InteractionCoxDiagnostics()
    diagnostics.comprehensive_interaction_diagnostics()

if __name__ == "__main__":
    main()