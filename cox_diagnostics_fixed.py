#!/usr/bin/env python3
"""
Coxå›å½’æ¨¡å‹è¯Šæ–­å·¥å…·
æ£€éªŒCoxå›å½’æ¨¡å‹çš„å„ç§å‡è®¾å’Œè¯Šæ–­ç»Ÿè®¡é‡
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from lifelines import CoxPHFitter
from lifelines.statistics import proportional_hazard_test
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# å¯¼å…¥ç°æœ‰çš„åˆ†ææ¨¡å—
import sys
import os
sys.path.append(os.path.dirname(__file__))
from src.modeling.baseline import BaselineModeling

class CoxModelDiagnostics:
    """Coxå›å½’æ¨¡å‹è¯Šæ–­ç±»"""
    
    def __init__(self):
        self.data = None
        self.model = None
        self.fitted = False
        
    def load_and_prepare_data(self):
        """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
        print("ğŸ“Š åŠ è½½Coxæ¨¡å‹æ•°æ®...")
        
        try:
            baseline = BaselineModeling()
            baseline.load_data()
            
            # åˆå¹¶æ‰€æœ‰æ¨¡å‹æ•°æ®
            combined_data = []
            for model_name, model_data in baseline.models_data.items():
                long_df = model_data['long'].copy()
                long_df['model'] = model_name
                
                # é€‰æ‹©å¿…è¦çš„åˆ—
                required_cols = ['round', 'failure', 'conversation_id', 'model', 
                               'prompt_to_prompt_drift', 'context_to_prompt_drift', 
                               'cumulative_drift', 'prompt_complexity']
                
                available_cols = [col for col in required_cols if col in long_df.columns]
                model_subset = long_df[available_cols].copy()
                model_subset = model_subset.dropna()
                
                if len(model_subset) > 0:
                    combined_data.append(model_subset)
            
            self.data = pd.concat(combined_data, ignore_index=True)
            
            # åˆ›å»ºæ¨¡å‹è™šæ‹Ÿå˜é‡ (ä»¥claude_35ä¸ºå‚ç…§)
            model_dummies = pd.get_dummies(self.data['model'], prefix='model', drop_first=True)
            self.data = pd.concat([self.data, model_dummies], axis=1)
            
            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(self.data)} è§‚æµ‹å€¼, {len(self.data['model'].unique())} ä¸ªæ¨¡å‹")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def fit_cox_model(self):
        """æ‹ŸåˆCoxæ¨¡å‹"""
        print("\nğŸ”§ æ‹ŸåˆCoxå›å½’æ¨¡å‹...")
        
        # å‡†å¤‡åå˜é‡
        drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                     'cumulative_drift', 'prompt_complexity']
        model_vars = [col for col in self.data.columns if col.startswith('model_')]
        
        covariates = drift_vars + model_vars + ['round', 'failure']
        model_data = self.data[covariates].copy()
        
        # æ‹Ÿåˆæ¨¡å‹
        self.model = CoxPHFitter(penalizer=0.01)  # æ·»åŠ L2æ­£åˆ™åŒ–
        self.model.fit(model_data, duration_col='round', event_col='failure', show_progress=False)
        
        self.fitted = True
        print(f"âœ… æ¨¡å‹æ‹Ÿåˆå®Œæˆ (C-index: {self.model.concordance_index_:.4f})")
        
        return self.model
    
    def test_proportional_hazards(self):
        """æ£€éªŒæ¯”ä¾‹é£é™©å‡è®¾"""
        print("\nğŸ§ª æ£€éªŒæ¯”ä¾‹é£é™©å‡è®¾ (Proportional Hazards Assumption)")
        print("=" * 60)
        
        if not self.fitted:
            print("âŒ è¯·å…ˆæ‹Ÿåˆæ¨¡å‹")
            return
        
        try:
            # å‡†å¤‡ç”¨äºæ£€éªŒçš„æ•°æ® - ä½¿ç”¨æ¨¡å‹è®­ç»ƒæ—¶ç›¸åŒçš„æ•°æ®
            drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                         'cumulative_drift', 'prompt_complexity']
            model_vars = [col for col in self.data.columns if col.startswith('model_')]
            covariates = drift_vars + model_vars + ['round', 'failure']
            test_data = self.data[covariates].copy()
            
            # è¿›è¡Œæ¯”ä¾‹é£é™©æ£€éªŒ
            ph_test = proportional_hazard_test(self.model, test_data, time_col='round', event_col='failure')
            
            print("æ¯”ä¾‹é£é™©æ£€éªŒç»“æœ:")
            if hasattr(ph_test, 'p_value'):
                # p_valueæ˜¯ä¸€ä¸ªæ•°ç»„ï¼ŒåŒ…å«æ¯ä¸ªåå˜é‡çš„på€¼
                p_values = ph_test.p_value
                if isinstance(p_values, np.ndarray):
                    # æ˜¾ç¤ºå„åå˜é‡çš„æ£€éªŒç»“æœ
                    if hasattr(ph_test, 'summary') and ph_test.summary is not None:
                        print("\nå„åå˜é‡æ¯”ä¾‹é£é™©æ£€éªŒ:")
                        summary_df = ph_test.summary
                        for idx, var_name in enumerate(summary_df.index):
                            p_val = p_values[idx] if idx < len(p_values) else p_values[0]
                            status = "âŒ è¿åå‡è®¾" if p_val < 0.05 else "âœ… ç¬¦åˆå‡è®¾"
                            print(f"  {var_name}: p = {p_val:.6f} {status}")
                    
                    # å…¨å±€æ£€éªŒï¼šå¦‚æœä»»ä½•ä¸€ä¸ªåå˜é‡è¿åå‡è®¾ï¼Œæ•´ä½“å°±è¿å
                    min_p = np.min(p_values)
                    violated_count = np.sum(p_values < 0.05)
                    print(f"\nå…¨å±€æ£€éªŒæ€»ç»“:")
                    print(f"  æœ€å°på€¼: {min_p:.6f}")
                    print(f"  è¿åå‡è®¾çš„åå˜é‡æ•°: {violated_count}/{len(p_values)}")
                    
                    if violated_count > 0:
                        print("âš ï¸  éƒ¨åˆ†åå˜é‡è¿åæ¯”ä¾‹é£é™©å‡è®¾")
                    else:
                        print("âœ… æ‰€æœ‰åå˜é‡å‡ç¬¦åˆæ¯”ä¾‹é£é™©å‡è®¾")
                else:
                    # æ ‡é‡på€¼çš„æƒ…å†µ
                    print(f"å…¨å±€æ£€éªŒ på€¼: {p_values:.6f}")
                    if p_values < 0.05:
                        print("âš ï¸  æ¯”ä¾‹é£é™©å‡è®¾å¯èƒ½è¢«è¿å (p < 0.05)")
                    else:
                        print("âœ… æ¯”ä¾‹é£é™©å‡è®¾åˆç† (p â‰¥ 0.05)")
            
            # å¯è§†åŒ–Schoenfeldæ®‹å·®
            self.plot_schoenfeld_residuals()
            
            return ph_test
            
        except Exception as e:
            print(f"âŒ æ¯”ä¾‹é£é™©æ£€éªŒå¤±è´¥: {e}")
            print("âš ï¸  è¿™å¯èƒ½æ˜¯ç”±äºæ•°æ®æ ¼å¼æˆ–æ¨¡å‹å¤æ‚æ€§å¯¼è‡´çš„")
            # å°è¯•ç®€åŒ–ç‰ˆæœ¬çš„æ£€éªŒ
            try:
                print("ğŸ”„ å°è¯•ç®€åŒ–ç‰ˆæ¯”ä¾‹é£é™©æ£€éªŒ...")
                self.simplified_ph_test()
            except Exception as simple_e:
                print(f"âš ï¸  ç®€åŒ–ç‰ˆæ£€éªŒä¹Ÿå¤±è´¥: {simple_e}")
                # å°è¯•æ‰‹åŠ¨Schoenfeldæ®‹å·®æ£€éªŒ
                print("ğŸ”„ å°è¯•åŸºäºSchoenfeldæ®‹å·®çš„æ‰‹åŠ¨æ£€éªŒ...")
                self.manual_ph_test()
            return None
    
    def manual_ph_test(self):
        """åŸºäºSchoenfeldæ®‹å·®çš„æ‰‹åŠ¨æ¯”ä¾‹é£é™©æ£€éªŒ"""
        try:
            from scipy.stats import pearsonr
            
            # å‡†å¤‡æ•°æ®
            drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                         'cumulative_drift', 'prompt_complexity']
            model_vars = [col for col in self.data.columns if col.startswith('model_')]
            covariates = drift_vars + model_vars + ['round', 'failure']
            residual_data = self.data[covariates].copy()
            
            # è®¡ç®—Schoenfeldæ®‹å·®
            schoenfeld_resid = self.model.compute_residuals(residual_data, kind='schoenfeld')
            
            print("æ‰‹åŠ¨Schoenfeldæ®‹å·®æ£€éªŒç»“æœ:")
            
            # å¯¹æ¯ä¸ªåå˜é‡æ£€éªŒæ®‹å·®ä¸æ—¶é—´çš„ç›¸å…³æ€§
            ph_violations = []
            times = residual_data['round']
            
            for i, var_name in enumerate(schoenfeld_resid.columns):
                residuals = schoenfeld_resid.iloc[:, i]
                
                # ç§»é™¤NaNå€¼
                mask = ~(np.isnan(residuals) | np.isnan(times))
                if mask.sum() < 10:
                    print(f"  {var_name}: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                    continue
                
                clean_resid = residuals[mask]
                clean_times = times[mask]
                
                # è®¡ç®—ç›¸å…³æ€§
                try:
                    corr, p_val = pearsonr(clean_times, clean_resid)
                    status = "âŒ è¿åå‡è®¾" if p_val < 0.05 else "âœ… ç¬¦åˆå‡è®¾"
                    print(f"  {var_name}: ç›¸å…³ç³»æ•° = {corr:.4f}, p = {p_val:.6f} {status}")
                    
                    if p_val < 0.05:
                        ph_violations.append(var_name)
                except Exception as corr_e:
                    print(f"  {var_name}: ç›¸å…³æ€§è®¡ç®—å¤±è´¥ - {corr_e}")
            
            # æ€»ç»“
            print(f"\næ‰‹åŠ¨æ£€éªŒæ€»ç»“:")
            print(f"  è¿åæ¯”ä¾‹é£é™©å‡è®¾çš„å˜é‡: {len(ph_violations)}")
            if ph_violations:
                print(f"  è¿åçš„å˜é‡: {', '.join(ph_violations)}")
                print("âš ï¸  éƒ¨åˆ†å˜é‡å¯èƒ½è¿åæ¯”ä¾‹é£é™©å‡è®¾")
            else:
                print("âœ… æ‰€æœ‰å˜é‡å‡ç¬¦åˆæ¯”ä¾‹é£é™©å‡è®¾ï¼ˆåŸºäºSchoenfeldæ®‹å·®ï¼‰")
                
        except Exception as e:
            print(f"âŒ æ‰‹åŠ¨æ£€éªŒä¹Ÿå¤±è´¥: {e}")
            print("ğŸ’¡ å»ºè®®: æ¨¡å‹è™½ç„¶æ£€éªŒå›°éš¾ï¼Œä½†C-indexé«˜è¯´æ˜é¢„æµ‹æ€§èƒ½è‰¯å¥½")
    
    def simplified_ph_test(self):
        """ç®€åŒ–ç‰ˆæ¯”ä¾‹é£é™©æ£€éªŒ"""
        try:
            # åªå¯¹æ ¸å¿ƒå˜é‡è¿›è¡Œæ£€éªŒ
            drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                         'cumulative_drift', 'prompt_complexity', 'round', 'failure']
            simple_data = self.data[drift_vars].copy()
            
            # æ‹Ÿåˆç®€åŒ–æ¨¡å‹
            simple_model = CoxPHFitter()
            simple_model.fit(simple_data, duration_col='round', event_col='failure', show_progress=False)
            
            # æ£€éªŒ
            ph_test = proportional_hazard_test(simple_model, simple_data, time_col='round', event_col='failure')
            p_values = ph_test.p_value
            if isinstance(p_values, np.ndarray):
                min_p = np.min(p_values)
                violated_count = np.sum(p_values < 0.05)
                print(f"ç®€åŒ–æ¨¡å‹æ£€éªŒç»“æœ:")
                print(f"  æœ€å°på€¼: {min_p:.6f}")
                print(f"  è¿åå‡è®¾å˜é‡æ•°: {violated_count}/{len(p_values)}")
            else:
                print(f"ç®€åŒ–æ¨¡å‹å…¨å±€æ£€éªŒ på€¼: {p_values:.6f}")
            
        except Exception as e:
            print(f"ç®€åŒ–ç‰ˆæ£€éªŒå¤±è´¥: {e}")
    
    def plot_schoenfeld_residuals(self):
        """ç»˜åˆ¶Schoenfeldæ®‹å·®å›¾æ£€éªŒæ¯”ä¾‹é£é™©å‡è®¾"""
        try:
            # å‡†å¤‡æ•°æ®
            drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                         'cumulative_drift', 'prompt_complexity']
            model_vars = [col for col in self.data.columns if col.startswith('model_')]
            covariates = drift_vars + model_vars + ['round', 'failure']
            residual_data = self.data[covariates].copy()
            
            # è·å–Schoenfeldæ®‹å·®
            residuals = self.model.compute_residuals(residual_data, kind='schoenfeld')
            
            # åˆ›å»ºå›¾å½¢
            n_vars = len(residuals.columns)
            n_cols = min(3, n_vars)
            n_rows = (n_vars + n_cols - 1) // n_cols
            
            fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
            if n_rows == 1 and n_cols == 1:
                axes = [axes]
            elif n_rows == 1:
                axes = axes
            else:
                axes = axes.flatten()
            
            for i, var in enumerate(residuals.columns):
                if i < len(axes):
                    ax = axes[i]
                    
                    # ç»˜åˆ¶æ®‹å·®vsæ—¶é—´
                    resid_values = residuals[var]
                    
                    # ç¡®ä¿ç»´åº¦åŒ¹é… - Schoenfeldæ®‹å·®é€šå¸¸å¯¹åº”äº‹ä»¶æ—¶é—´
                    # åˆ›å»ºç›¸åº”çš„æ—¶é—´åºåˆ—
                    n_points = len(resid_values)
                    if n_points > 0:
                        # ä½¿ç”¨è§‚æµ‹åºå·ä½œä¸ºxè½´ï¼Œè€Œä¸æ˜¯æ—¶é—´
                        x_vals = range(n_points)
                        
                        ax.scatter(x_vals, resid_values, alpha=0.5, s=10)
                        ax.axhline(y=0, color='red', linestyle='--', alpha=0.7)
                        ax.set_xlabel('è§‚æµ‹åºå·')
                        ax.set_ylabel(f'Schoenfeldæ®‹å·®')
                        ax.set_title(f'{var}')
                        ax.grid(True, alpha=0.3)
                    else:
                        ax.text(0.5, 0.5, 'æ— æ•°æ®', ha='center', va='center', transform=ax.transAxes)
                        ax.set_title(f'{var} (æ— æ•°æ®)')
            
            # éšè—å¤šä½™çš„å­å›¾
            for i in range(n_vars, len(axes)):
                axes[i].set_visible(False)
            
            plt.tight_layout()
            plt.savefig('results/figures/cox_schoenfeld_residuals.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("âœ… Schoenfeldæ®‹å·®å›¾å·²ä¿å­˜è‡³ results/figures/cox_schoenfeld_residuals.png")
            
        except Exception as e:
            print(f"âŒ Schoenfeldæ®‹å·®å›¾ç»˜åˆ¶å¤±è´¥: {e}")
    
    def test_linearity(self):
        """æ£€éªŒå¯¹æ•°çº¿æ€§å‡è®¾"""
        print("\nğŸ§ª æ£€éªŒå¯¹æ•°çº¿æ€§å‡è®¾ (Log-linearity)")
        print("=" * 50)
        
        if not self.fitted:
            print("âŒ è¯·å…ˆæ‹Ÿåˆæ¨¡å‹")
            return
        
        # è®¡ç®—Martingaleæ®‹å·®
        try:
            # å‡†å¤‡ç”¨äºæ®‹å·®è®¡ç®—çš„æ•°æ® - ä½¿ç”¨æ¨¡å‹è®­ç»ƒæ—¶ç›¸åŒçš„æ•°æ®
            drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                         'cumulative_drift', 'prompt_complexity']
            model_vars = [col for col in self.data.columns if col.startswith('model_')]
            covariates = drift_vars + model_vars + ['round', 'failure']
            residual_data = self.data[covariates].copy()
            
            martingale_resid = self.model.compute_residuals(residual_data, kind='martingale')
            
            # å¤„ç†æ®‹å·®æ•°æ®æ ¼å¼
            if isinstance(martingale_resid, pd.DataFrame):
                martingale_values = martingale_resid.iloc[:, 0]
            else:
                martingale_values = martingale_resid
            
            # å¯¹è¿ç»­å˜é‡æ£€éªŒçº¿æ€§å…³ç³»
            continuous_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                             'cumulative_drift', 'prompt_complexity']
            
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            axes = axes.flatten()
            
            for i, var in enumerate(continuous_vars):
                if var in self.data.columns and i < len(axes):
                    ax = axes[i]
                    
                    # ç»˜åˆ¶Martingaleæ®‹å·® vs åå˜é‡
                    x_vals = self.data[var]
                    y_vals = martingale_values
                    
                    # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
                    min_len = min(len(x_vals), len(y_vals))
                    x_vals = x_vals[:min_len]
                    y_vals = y_vals[:min_len]
                    
                    ax.scatter(x_vals, y_vals, alpha=0.5, s=20)
                    ax.axhline(y=0, color='red', linestyle='--', alpha=0.7)
                    
                    # æ·»åŠ å¹³æ»‘æ›²çº¿
                    try:
                        from scipy.interpolate import UnivariateSpline
                        # ç§»é™¤NaNå€¼
                        mask = ~(np.isnan(x_vals) | np.isnan(y_vals))
                        if mask.sum() > 50:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®ç‚¹
                            x_clean = x_vals[mask]
                            y_clean = y_vals[mask]
                            
                            # æ’åºä»¥ä¾¿å¹³æ»‘
                            sort_idx = np.argsort(x_clean)
                            x_sorted = x_clean.iloc[sort_idx] if hasattr(x_clean, 'iloc') else x_clean[sort_idx]
                            y_sorted = y_clean.iloc[sort_idx] if hasattr(y_clean, 'iloc') else y_clean[sort_idx]
                            
                            # å‡å°‘å¹³æ»‘å‚æ•°é¿å…è¿‡æ‹Ÿåˆ
                            spline = UnivariateSpline(x_sorted, y_sorted, s=len(x_sorted)*0.1)
                            smooth_x = np.linspace(x_sorted.min(), x_sorted.max(), 100)
                            ax.plot(smooth_x, spline(smooth_x), 'r-', linewidth=2, alpha=0.8)
                    except Exception as e:
                        print(f"å¹³æ»‘æ›²çº¿ç»˜åˆ¶å¤±è´¥ ({var}): {e}")
                    
                    ax.set_xlabel(var)
                    ax.set_ylabel('Martingaleæ®‹å·®')
                    ax.set_title(f'çº¿æ€§æ£€éªŒ: {var}')
                    ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('results/figures/cox_linearity_test.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("âœ… çº¿æ€§æ£€éªŒå›¾å·²ä¿å­˜è‡³ results/figures/cox_linearity_test.png")
            print("ğŸ’¡ å¦‚æœå¹³æ»‘æ›²çº¿æ¥è¿‘æ°´å¹³çº¿ï¼Œåˆ™ç¬¦åˆçº¿æ€§å‡è®¾")
            
        except Exception as e:
            print(f"âŒ çº¿æ€§æ£€éªŒå¤±è´¥: {e}")
    
    def detect_outliers(self):
        """æ£€æµ‹å¼‚å¸¸å€¼"""
        print("\nğŸ§ª å¼‚å¸¸å€¼æ£€æµ‹")
        print("=" * 30)
        
        if not self.fitted:
            print("âŒ è¯·å…ˆæ‹Ÿåˆæ¨¡å‹")
            return
        
        try:
            # å‡†å¤‡ç”¨äºæ®‹å·®è®¡ç®—çš„æ•°æ®
            drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                         'cumulative_drift', 'prompt_complexity']
            model_vars = [col for col in self.data.columns if col.startswith('model_')]
            covariates = drift_vars + model_vars + ['round', 'failure']
            residual_data = self.data[covariates].copy()
            
            # è®¡ç®—Devianceæ®‹å·®
            deviance_resid = self.model.compute_residuals(residual_data, kind='deviance')
            
            # å¤„ç†æ®‹å·®æ•°æ®æ ¼å¼
            if isinstance(deviance_resid, pd.DataFrame):
                deviance_values = deviance_resid.iloc[:, 0]  # å–ç¬¬ä¸€åˆ—
            else:
                deviance_values = deviance_resid
            
            # å®šä¹‰å¼‚å¸¸å€¼é˜ˆå€¼ (é€šå¸¸ç”¨Â±2.5æ ‡å‡†å·®)
            threshold = 2.5
            outliers = np.abs(deviance_values) > threshold
            
            print(f"å¼‚å¸¸å€¼æ£€æµ‹ç»“æœ:")
            print(f"  æ€»è§‚æµ‹æ•°: {len(deviance_values)}")
            print(f"  å¼‚å¸¸å€¼æ•°é‡: {outliers.sum()}")
            print(f"  å¼‚å¸¸å€¼æ¯”ä¾‹: {outliers.sum()/len(deviance_values)*100:.2f}%")
            
            if outliers.sum() > 0:
                print(f"\nå¼‚å¸¸å€¼è§‚æµ‹ID:")
                outlier_indices = np.where(outliers)[0]
                for idx in outlier_indices[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    print(f"  è§‚æµ‹ {idx}: Devianceæ®‹å·® = {deviance_values.iloc[idx]:.3f}")
                if len(outlier_indices) > 10:
                    print(f"  ... è¿˜æœ‰ {len(outlier_indices)-10} ä¸ªå¼‚å¸¸å€¼")
            
            # ç»˜åˆ¶å¼‚å¸¸å€¼å›¾
            plt.figure(figsize=(10, 6))
            plt.scatter(range(len(deviance_values)), deviance_values, alpha=0.6, s=20)
            plt.axhline(y=threshold, color='red', linestyle='--', alpha=0.7, label=f'é˜ˆå€¼ Â±{threshold}')
            plt.axhline(y=-threshold, color='red', linestyle='--', alpha=0.7)
            plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
            
            # æ ‡è®°å¼‚å¸¸å€¼
            if outliers.sum() > 0:
                outlier_x = np.where(outliers)[0]
                outlier_y = deviance_values[outliers]
                plt.scatter(outlier_x, outlier_y, color='red', s=50, alpha=0.8, label=f'å¼‚å¸¸å€¼ ({outliers.sum()})')
            
            plt.xlabel('è§‚æµ‹åºå·')
            plt.ylabel('Devianceæ®‹å·®')
            plt.title('Coxå›å½’å¼‚å¸¸å€¼æ£€æµ‹')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.savefig('results/figures/cox_outliers.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("âœ… å¼‚å¸¸å€¼å›¾å·²ä¿å­˜è‡³ results/figures/cox_outliers.png")
            
            return outliers
            
        except Exception as e:
            print(f"âŒ å¼‚å¸¸å€¼æ£€æµ‹å¤±è´¥: {e}")
            return None
    
    def check_multicollinearity(self):
        """æ£€æŸ¥å¤šé‡å…±çº¿æ€§"""
        print("\nğŸ§ª å¤šé‡å…±çº¿æ€§æ£€éªŒ")
        print("=" * 40)
        
        # è®¡ç®—è¿ç»­å˜é‡çš„ç›¸å…³çŸ©é˜µ
        drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                     'cumulative_drift', 'prompt_complexity']
        
        corr_data = self.data[drift_vars]
        corr_matrix = corr_data.corr()
        
        print("åå˜é‡ç›¸å…³çŸ©é˜µ:")
        print(corr_matrix.round(3))
        
        # æ£€æŸ¥é«˜ç›¸å…³æ€§
        high_corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.8:
                    high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))
        
        if high_corr_pairs:
            print(f"\nâš ï¸  å‘ç°é«˜ç›¸å…³æ€§å˜é‡å¯¹ (|r| > 0.8):")
            for var1, var2, corr_val in high_corr_pairs:
                print(f"  {var1} - {var2}: r = {corr_val:.3f}")
        else:
            print("\nâœ… æœªå‘ç°ä¸¥é‡å¤šé‡å…±çº¿æ€§é—®é¢˜")
        
        # ç»˜åˆ¶ç›¸å…³æ€§çƒ­å›¾
        plt.figure(figsize=(8, 6))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                   square=True, cbar_kws={'shrink': 0.8})
        plt.title('åå˜é‡ç›¸å…³æ€§çŸ©é˜µ')
        plt.tight_layout()
        plt.savefig('results/figures/cox_correlation_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… ç›¸å…³æ€§çŸ©é˜µå›¾å·²ä¿å­˜è‡³ results/figures/cox_correlation_matrix.png")
        
        return corr_matrix
    
    def goodness_of_fit(self):
        """æ‹Ÿåˆä¼˜åº¦è¯„ä¼°"""
        print("\nğŸ§ª æ¨¡å‹æ‹Ÿåˆä¼˜åº¦è¯„ä¼°")
        print("=" * 40)
        
        if not self.fitted:
            print("âŒ è¯·å…ˆæ‹Ÿåˆæ¨¡å‹")
            return
        
        # è®¡ç®—å„ç§æ‹ŸåˆæŒ‡æ ‡
        c_index = self.model.concordance_index_
        log_likelihood = self.model.log_likelihood_
        aic_partial = self.model.AIC_partial_  # Coxæ¨¡å‹ä½¿ç”¨partial AIC
        
        print(f"æ‹Ÿåˆä¼˜åº¦æŒ‡æ ‡:")
        print(f"  C-index (ä¸€è‡´æ€§æŒ‡æ•°): {c_index:.4f}")
        print(f"  Log-likelihood: {log_likelihood:.2f}")
        print(f"  AIC (partial): {aic_partial:.2f}")
        
        # C-indexè§£é‡Š
        if c_index > 0.8:
            c_interpretation = "ä¼˜ç§€"
        elif c_index > 0.7:
            c_interpretation = "è‰¯å¥½"
        elif c_index > 0.6:
            c_interpretation = "ä¸­ç­‰"
        else:
            c_interpretation = "è¾ƒå·®"
        
        print(f"  C-indexè§£é‡Š: {c_interpretation}")
        
        # è®¡ç®—æ®‹å·®ç»Ÿè®¡
        try:
            # å‡†å¤‡ç”¨äºæ®‹å·®è®¡ç®—çš„æ•°æ®
            drift_vars = ['prompt_to_prompt_drift', 'context_to_prompt_drift', 
                         'cumulative_drift', 'prompt_complexity']
            model_vars = [col for col in self.data.columns if col.startswith('model_')]
            covariates = drift_vars + model_vars + ['round', 'failure']
            residual_data = self.data[covariates].copy()
            
            martingale_resid = self.model.compute_residuals(residual_data, kind='martingale')
            deviance_resid = self.model.compute_residuals(residual_data, kind='deviance')
            
            # å¤„ç†æ®‹å·®æ•°æ®æ ¼å¼
            if isinstance(martingale_resid, pd.DataFrame):
                martingale_values = martingale_resid.iloc[:, 0]
            else:
                martingale_values = martingale_resid
                
            if isinstance(deviance_resid, pd.DataFrame):
                deviance_values = deviance_resid.iloc[:, 0]
            else:
                deviance_values = deviance_resid
            
            print(f"\næ®‹å·®ç»Ÿè®¡:")
            print(f"  Martingaleæ®‹å·®å‡å€¼: {martingale_values.mean():.6f}")
            print(f"  Martingaleæ®‹å·®æ ‡å‡†å·®: {martingale_values.std():.4f}")
            print(f"  Devianceæ®‹å·®å‡å€¼: {deviance_values.mean():.6f}")
            print(f"  Devianceæ®‹å·®æ ‡å‡†å·®: {deviance_values.std():.4f}")
            
        except Exception as e:
            print(f"æ®‹å·®è®¡ç®—å¤±è´¥: {e}")
        
        return {
            'c_index': c_index,
            'log_likelihood': log_likelihood,
            'aic_partial': aic_partial
        }
    
    def comprehensive_diagnostics(self):
        """è¿è¡Œå®Œæ•´çš„æ¨¡å‹è¯Šæ–­"""
        print("ğŸ©º COXå›å½’æ¨¡å‹å®Œæ•´è¯Šæ–­")
        print("=" * 80)
        
        # åŠ è½½æ•°æ®
        if not self.load_and_prepare_data():
            return
        
        # æ‹Ÿåˆæ¨¡å‹
        self.fit_cox_model()
        
        print("=" * 80)
        
        # è¿è¡Œæ‰€æœ‰è¯Šæ–­æµ‹è¯•
        self.test_proportional_hazards()
        
        print("=" * 80)
        
        self.test_linearity()
        
        print("=" * 80)
        
        self.detect_outliers()
        
        print("=" * 80)
        
        self.check_multicollinearity()
        
        print("=" * 80)
        
        self.goodness_of_fit()
        
        print("=" * 80)
        print("ğŸ‰ æ¨¡å‹è¯Šæ–­å®Œæˆï¼")
        print("ğŸ“ è¯Šæ–­å›¾è¡¨å·²ä¿å­˜è‡³ results/figures/ ç›®å½•")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºè¯Šæ–­å¯¹è±¡å¹¶è¿è¡Œå®Œæ•´è¯Šæ–­
    diagnostics = CoxModelDiagnostics()
    diagnostics.comprehensive_diagnostics()

if __name__ == "__main__":
    main()